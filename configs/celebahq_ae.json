{
  "_comment": "Taxonomic CelebA-HQ autoencoder matching CIFAR-10 architecture pattern with hierarchical filters",
  "description": "CelebA-HQ Taxonomic Autoencoder: 8 encoder layers (4 blocks × 2) and 8 decoder layers (4 blocks × 2), spatial latent 16x16x255",
  "experiment_name": "celebahq_taxonomic",
  "data": {
    "data_root": "./data/celeba_hq",
    "batch_size": 128,
    "num_workers": 4,
    "val_split": 0.1,
    "train_subset": 5000,
    "val_subset": 1000,
    "_comment_subset": "Using full dataset now - 5k was too small for learning color diversity. Reduced batch_size to 64 to fit in memory."
  },
  "model": {
    "latent_dim": 256,
    "temperature": 1.0,
    "use_maxpool": true,
    "output_activation": "sigmoid",
    "encoder_layers": [
      {
        "layer_type": "taxonomic_conv",
        "n_layers": 5,
        "kernel_size": 3,
        "stride": 1,
        "padding": 1,
        "_comment": "Block 1, Layer 1: 256x256x3 -> 256x256x31 (2^5=32 leaf filters)"
      },
      {
        "layer_type": "taxonomic_conv",
        "n_layers": 5,
        "kernel_size": 3,
        "stride": 2,
        "padding": 1,
        "_comment": "Block 1, Layer 2: 256x256x31 -> MaxPool -> 128x128x31"
      },
      {
        "layer_type": "taxonomic_conv",
        "n_layers": 6,
        "kernel_size": 3,
        "stride": 1,
        "padding": 1,
        "_comment": "Block 2, Layer 1: 128x128x31 -> 128x128x63 (2^6=64 leaf filters)"
      },
      {
        "layer_type": "taxonomic_conv",
        "n_layers": 6,
        "kernel_size": 3,
        "stride": 2,
        "padding": 1,
        "_comment": "Block 2, Layer 2: 128x128x63 -> MaxPool -> 64x64x63"
      },
      {
        "layer_type": "taxonomic_conv",
        "n_layers": 7,
        "kernel_size": 3,
        "stride": 1,
        "padding": 1,
        "_comment": "Block 3, Layer 1: 64x64x63 -> 64x64x127 (2^7=128 leaf filters)"
      },
      {
        "layer_type": "taxonomic_conv",
        "n_layers": 7,
        "kernel_size": 3,
        "stride": 2,
        "padding": 1,
        "_comment": "Block 3, Layer 2: 64x64x127 -> MaxPool -> 32x32x127"
      },
      {
        "layer_type": "taxonomic_conv",
        "n_layers": 8,
        "kernel_size": 3,
        "stride": 1,
        "padding": 1,
        "_comment": "Block 4, Layer 1: 32x32x127 -> 32x32x255 (2^8=256 leaf filters)"
      },
      {
        "layer_type": "taxonomic_conv",
        "n_layers": 8,
        "kernel_size": 3,
        "stride": 2,
        "padding": 1,
        "_comment": "Block 4, Layer 2 (latent): 32x32x255 -> MaxPool -> 16x16x255"
      }
    ],
    "decoder_layers": [
      {
        "layer_type": "taxonomic_deconv",
        "n_layers": 8,
        "kernel_size": 3,
        "stride": 2,
        "padding": 1,
        "output_padding": 1,
        "_comment": "Block 1, Layer 1 (DECONV - upsample): 16x16x255 -> 32x32x255 (2^8=256 leaf filters)"
      },
      {
        "layer_type": "taxonomic_conv",
        "n_layers": 7,
        "kernel_size": 3,
        "stride": 1,
        "padding": 1,
        "output_padding": 0,
        "_comment": "Block 1, Layer 2 (CONV - refine): 32x32x255 -> 32x32x127 (2^7=128 leaf filters)"
      },
      {
        "layer_type": "taxonomic_deconv",
        "n_layers": 7,
        "kernel_size": 3,
        "stride": 2,
        "padding": 1,
        "output_padding": 1,
        "_comment": "Block 2, Layer 1 (DECONV - upsample): 32x32x127 -> 64x64x127 (2^7=128 leaf filters)"
      },
      {
        "layer_type": "taxonomic_conv",
        "n_layers": 6,
        "kernel_size": 3,
        "stride": 1,
        "padding": 1,
        "output_padding": 0,
        "_comment": "Block 2, Layer 2 (CONV - refine): 64x64x127 -> 64x64x63 (2^6=64 leaf filters)"
      },
      {
        "layer_type": "taxonomic_deconv",
        "n_layers": 6,
        "kernel_size": 3,
        "stride": 2,
        "padding": 1,
        "output_padding": 1,
        "_comment": "Block 3, Layer 1 (DECONV - upsample): 64x64x63 -> 128x128x63 (2^6=64 leaf filters)"
      },
      {
        "layer_type": "taxonomic_conv",
        "n_layers": 5,
        "kernel_size": 3,
        "stride": 1,
        "padding": 1,
        "output_padding": 0,
        "_comment": "Block 3, Layer 2 (CONV - refine): 128x128x63 -> 128x128x31 (2^5=32 leaf filters)"
      },
      {
        "layer_type": "taxonomic_deconv",
        "n_layers": 5,
        "kernel_size": 3,
        "stride": 2,
        "padding": 1,
        "output_padding": 1,
        "_comment": "Block 4, Layer 1 (DECONV - upsample): 128x128x31 -> 256x256x31 (2^5=32 leaf filters)"
      },
      {
        "layer_type": "taxonomic_conv",
        "n_layers": 5,
        "kernel_size": 3,
        "stride": 1,
        "padding": 1,
        "output_padding": 0,
        "_comment": "Block 4, Layer 2 (CONV - refine): 256x256x31 -> 256x256x31, then final conv to 256x256x3"
      }
    ]
  },
  "training": {
    "epochs": 20,
    "learning_rate": 0.001
  },
  "analysis": {
    "checkpoint_path": "outputs/celebahq/training/celebahq_taxonomic/final_model.pt",
    "num_latent_batches": 50,
    "num_reconstruction_batches": 20,
    "num_multiple_recon_images": 8,
    "num_reconstructions_per_image": 8,
    "num_activation_images": 3
  },
  "output": {
    "training_save_dir": "outputs/celebahq/training/celebahq_taxonomic",
    "analysis_save_dir": "outputs/celebahq/analysis/celebahq_taxonomic"
  }
}
